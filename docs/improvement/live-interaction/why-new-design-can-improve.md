# 為什麼 Server VAD 能改善效能

本文件解釋目前實作（Manual VAD）與新方案（Server VAD）的差異，以及為何新方案能顯著降低延遲。

## 架構對比圖

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        目前實作 (Manual VAD)                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  User speaks    Frontend VAD     end_turn      Backend        Gemini       │
│      │          (1s silence)     message       forwards       processes    │
│      │               │              │             │              │          │
│      ▼               ▼              ▼             ▼              ▼          │
│  ════════════════════════════════════════════════════════════════════►     │
│  │←── 說話 ──→│←─ 靜音1s ─→│←─ WS ─→│←─ 轉發 ─→│←─ AI處理 ─→│            │
│                                                                             │
│  總延遲 = 說話時間 + 1000ms靜音 + ~50ms WS + ~50ms轉發 + AI處理時間         │
│                     ~~~~~~~~                                                │
│                     這段是浪費                                               │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                        新方案 (Server VAD)                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  User speaks         Gemini VAD detects          Gemini processes          │
│      │               end-of-speech                    │                     │
│      ▼                    ▼                           ▼                     │
│  ═══════════════════════════════════════════════════════════════►          │
│  │←───── 說話 ─────→│←─ ~700ms ─→│←────── AI處理 ──────→│                  │
│                                                                             │
│  總延遲 = 說話時間 + 700ms靜音(可調) + AI處理時間                            │
│                      ~~~~~~~~~~~~                                           │
│                      直接在 Gemini 端偵測，無需來回傳輸                       │
└─────────────────────────────────────────────────────────────────────────────┘
```

## 詳細差異對比

| 面向 | 目前實作 (Manual VAD) | 新方案 (Server VAD) |
|------|----------------------|---------------------|
| **靜音偵測位置** | Frontend (瀏覽器) | Gemini Server |
| **靜音時長** | 固定 1000ms (`SILENCE_DURATION_MS`) | 可調 500-1000ms (`silence_duration_ms`) |
| **訊號傳輸** | Frontend → Backend → Gemini (2 hops) | Gemini 內部 (0 hops) |
| **activity_start** | 第一個 audio chunk 時發送 | 不需要 |
| **turn_complete** | Frontend 靜音後發送 | 不需要，Gemini 自動判斷 |
| **狀態同步** | Frontend 主導，可能與 Server 不同步 | Server 主導，Frontend 跟隨 |
| **Barge-in** | 手動按鈕 + 音量偵測 | Gemini 原生支援 + Frontend 輔助 |

## 目前程式碼流程（延遲來源標註）

```
┌─────────────────────────────────────────────────────────────────────────┐
│ 1. 用戶說話                                                              │
│    InteractionPanel.tsx L459-509                                        │
│    onAudioChunk → sendBinary (持續發送音訊)                              │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│ 2. Frontend VAD 靜音偵測                                                 │
│    InteractionPanel.tsx L576-599                                        │
│                                                                         │
│    if (silenceDuration >= SILENCE_DURATION_MS) {  // 等待 1000ms ⚠️     │
│      sendMessage('end_turn', {})                                        │
│      setInteractionState('processing')                                  │
│    }                                                                    │
│                                                                         │
│    ⚠️ 延遲來源 #1: 必須等待 1000ms 靜音才能確認用戶說完                    │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼ WebSocket ~20-50ms
┌─────────────────────────────────────────────────────────────────────────┐
│ 3. Backend 收到 end_turn                                                │
│    interaction_handler.py (處理 WebSocket 訊息)                          │
│                                                                         │
│    ⚠️ 延遲來源 #2: WebSocket 傳輸延遲                                    │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│ 4. Backend 發送 client_content.turn_complete 給 Gemini                  │
│    gemini_realtime.py L300-327                                          │
│                                                                         │
│    message = {                                                          │
│        "client_content": {                                              │
│            "turns": [],                                                 │
│            "turn_complete": True  // 告訴 Gemini 用戶說完了              │
│        }                                                                │
│    }                                                                    │
│                                                                         │
│    ⚠️ 延遲來源 #3: 額外的 WebSocket 訊息傳輸                              │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│ 5. Gemini 收到 turn_complete 後開始生成回應                              │
│    (Gemini 內部處理)                                                     │
└─────────────────────────────────────────────────────────────────────────┘
```

## 效能改善原因

### 1. 減少靜音等待時間

```python
# 目前 (Frontend)
SILENCE_DURATION_MS = 1000  # 固定 1 秒

# 新方案 (Gemini Server VAD)
"silence_duration_ms": 700  # 可調整，且 Gemini 的 VAD 更智慧
```

**改善**: 節省 **~300ms**（1000ms → 700ms）

### 2. 消除訊號來回傳輸延遲

```
目前流程:
  Frontend ──(end_turn)──> Backend ──(turn_complete)──> Gemini
            ~20-50ms              ~20-50ms

新方案:
  Gemini 內部直接偵測，無需等待外部訊號
```

**改善**: 節省 **~40-100ms**（2 次 WebSocket 傳輸）

### 3. 更精準的語音結束偵測

Gemini Server VAD 有以下優勢：

| 優勢 | 說明 |
|------|------|
| **聲學模型** | Gemini 使用深度學習模型判斷語音結束，比音量閾值更準確 |
| **上下文理解** | 可以根據語意判斷句子是否說完（例如「我想要...」還沒說完） |
| **即時處理** | 音訊串流直接在 Gemini 端分析，無需等待前端判斷 |
| **自適應** | 可以根據說話者的語速自動調整判斷標準 |

### 4. 消除狀態不同步問題

```typescript
// 目前問題: Frontend 和 Backend 狀態可能不同步
// Frontend 認為用戶在說話，但 Backend 已經在等待回應
// 導致 "BLOCKED" 狀態

// 新方案: Server 主導狀態
// Frontend 只是跟隨 Server 的事件
case 'speech_started':  // Server 說用戶開始說話
case 'speech_ended':    // Server 說用戶說完了
```

**改善**: 消除阻塞狀態，對話更流暢

## 延遲對比估算

| 階段 | 目前實作 | 新方案 | 節省 |
|------|---------|--------|------|
| 靜音偵測等待 | 1000ms | 700ms | 300ms |
| Frontend → Backend | ~30ms | 0ms | 30ms |
| Backend → Gemini | ~30ms | 0ms | 30ms |
| VAD 判斷延遲 | ~50ms (音量閾值) | ~0ms (即時) | 50ms |
| **總計** | **~1110ms** | **~700ms** | **~410ms** |

**預期改善: P50 延遲從 ~1500ms 降到 ~800ms（改善 ~47%）**

## 圖解：為什麼 Server VAD 更快

```
時間軸 (ms)    0    200   400   600   800   1000  1200  1400  1600
              │     │     │     │     │     │     │     │     │

Manual VAD:   │▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓│░░░░░░░░░░░░░░░░░│===│===│▒▒▒▒▒│
              │← 用戶說話 →│← Frontend等1s靜音 →│WS │WS │ AI  │
              │            │                    │來 │回 │ 處理│
              │            │        ⬆️           │   │   │     │
              │            │    這段時間完全浪費  │   │   │     │

Server VAD:   │▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓│░░░░░░░░░│▒▒▒▒▒▒▒▒▒▒▒▒▒│
              │← 用戶說話 →│← 700ms →│← AI 處理 →│
              │            │ Gemini  │           │
              │            │ 內部判斷│           │
              │                 ⬆️                │
              │     Gemini 邊聽邊判斷，無需等待外部訊號

圖例: ▓ 用戶說話  ░ 等待/偵測  === 網路傳輸  ▒ AI 處理
```

## 總結

| 改善面向 | 原因 |
|---------|------|
| **延遲降低 ~400ms** | 減少靜音等待時間 + 消除訊號傳輸 |
| **消除 BLOCKED 狀態** | Server 主導狀態，Frontend 跟隨 |
| **更自然的對話** | Gemini 智慧判斷語音結束，不會誤切 |
| **更好的 Barge-in** | Gemini 原生支援打斷，響應更快 |

## 相關文件

- [001-native-server-vad.md](./001-native-server-vad.md) - 完整實作計劃
